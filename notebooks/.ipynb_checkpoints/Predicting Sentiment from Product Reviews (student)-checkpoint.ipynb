{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting sentiment from product reviews\n",
    "\n",
    "\n",
    "The goal of this first notebook is to explore logistic regression and feature engineering with existing Sklearn, Pandas, and Numpy functions.\n",
    "\n",
    "In this notebook you will use product review data from Amazon.com to predict whether the sentiments about a product (from its reviews) are positive or negative.\n",
    "\n",
    "* Do some feature engineering\n",
    "* Train a logistic regression model to predict the sentiment of product reviews.\n",
    "* Inspect the weights (coefficients) of a trained logistic regression model.\n",
    "* Make a prediction (both class and probability) of sentiment for a new product review.\n",
    "* Given the logistic regression weights, predictors and ground truth labels, write a function to compute the **accuracy** of the model.\n",
    "* Inspect the coefficients of the logistic regression model and interpret their meanings.\n",
    "* Compare multiple logistic regression models.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "We will use a dataset consisting of Amazon.com product reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('../datasets/Amazon Product Reviews I.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us see a preview of what the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             reviews  rating  \\\n",
      "0  I initially had trouble deciding between the p...     5.0   \n",
      "1  Allow me to preface this with a little history...     5.0   \n",
      "2  I am enjoying it so far. Great for reading. Ha...     4.0   \n",
      "3  I bought one of the first Paperwhites and have...     5.0   \n",
      "4  I have to say upfront - I don't like coroporat...     5.0   \n",
      "\n",
      "                                        title  \n",
      "0              Paperwhite voyage, no regrets!  \n",
      "1           One Simply Could Not Ask For More  \n",
      "2  Great for those that just want an e-reader  \n",
      "3                    Love / Hate relationship  \n",
      "4                                   I LOVE IT  \n"
     ]
    }
   ],
   "source": [
    "# Simplify relevant columns names\n",
    "\n",
    "# Drop irrelevant columns\n",
    "\n",
    "# Drop Nana\n",
    "\n",
    "#print(products.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the word count vector for each review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explore a specific example of a Amazon product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can read a lot longer without pain in my hands since the cover holds it for me. Very nice shade of blue.\n"
     ]
    }
   ],
   "source": [
    "print(products['reviews'][269])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will perform 2 simple data transformations:\n",
    "\n",
    "1. Remove punctuation using [Python's built-in](https://docs.python.org/2/library/string.html) string functionality.\n",
    "2. Transform the reviews into word-counts.\n",
    "\n",
    "**Aside**. In this notebook, we remove all punctuations for the sake of simplicity. A smarter approach to punctuations would preserve phrases such as \"I'd\", \"would've\", \"hadn't\" and so forth. See [this page](https://neptune.ai/blog/tokenization-in-nlp) for an example of smart handling of punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       I initially had trouble deciding between the p...\n",
      "1       Allow me to preface this with a little history...\n",
      "2       I am enjoying it so far Great for reading Had ...\n",
      "3       I bought one of the first Paperwhites and have...\n",
      "4       I have to say upfront  I dont like coroporate ...\n",
      "                              ...                        \n",
      "1172    This is not the same remote that I got for my ...\n",
      "1173    I have had to change the batteries in this rem...\n",
      "1174    Remote did not activate nor did it connect to ...\n",
      "1175    It does the job but is super over priced I fee...\n",
      "1176    I ordered this item to replace the one that no...\n",
      "Name: reviews, Length: 1177, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "def remove_punctuation(text):\n",
    "    try: # python 2.x\n",
    "        text = text.translate(None, string.punctuation) \n",
    "    except: # python 3.x\n",
    "        translator = text.maketrans('', '', string.punctuation)\n",
    "        text = text.translate(translator)\n",
    "    return text\n",
    "\n",
    "products['reviews'] = products['reviews'].apply(remove_punctuation)\n",
    "print(products['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1177, 6750)\n",
      "(1177, 6750)\n",
      "                                             reviews  rating  \\\n",
      "0  I initially had trouble deciding between the p...     5.0   \n",
      "1  Allow me to preface this with a little history...     5.0   \n",
      "2  I am enjoying it so far Great for reading Had ...     4.0   \n",
      "3  I bought one of the first Paperwhites and have...     5.0   \n",
      "4  I have to say upfront  I dont like coroporate ...     5.0   \n",
      "\n",
      "                                        title  word_count_0  word_count_1  \\\n",
      "0              Paperwhite voyage, no regrets!           0.0           0.0   \n",
      "1           One Simply Could Not Ask For More           0.0           0.0   \n",
      "2  Great for those that just want an e-reader           0.0           0.0   \n",
      "3                    Love / Hate relationship           0.0           0.0   \n",
      "4                                   I LOVE IT           0.0           0.0   \n",
      "\n",
      "   word_count_2  word_count_3  word_count_4  word_count_5  word_count_6  ...  \\\n",
      "0           0.0           0.0           0.0           0.0           0.0  ...   \n",
      "1           0.0           0.0           0.0           0.0           0.0  ...   \n",
      "2           0.0           0.0           0.0           0.0           0.0  ...   \n",
      "3           0.0           0.0           0.0           0.0           0.0  ...   \n",
      "4           0.0           0.0           0.0           0.0           0.0  ...   \n",
      "\n",
      "   word_count_6740  word_count_6741  word_count_6742  word_count_6743  \\\n",
      "0              0.0              0.0              0.0              0.0   \n",
      "1              0.0              0.0              0.0              0.0   \n",
      "2              0.0              0.0              0.0              0.0   \n",
      "3              0.0              0.0              0.0              0.0   \n",
      "4              0.0              0.0              0.0              0.0   \n",
      "\n",
      "   word_count_6744  word_count_6745  word_count_6746  word_count_6747  \\\n",
      "0              0.0              0.0              0.0              0.0   \n",
      "1              0.0              0.0              0.0              0.0   \n",
      "2              0.0              0.0              0.0              0.0   \n",
      "3              0.0              0.0              0.0              0.0   \n",
      "4              0.0              0.0              0.0              0.0   \n",
      "\n",
      "   word_count_6748  word_count_6749  \n",
      "0              0.0              0.0  \n",
      "1              0.0              0.0  \n",
      "2              0.0              0.0  \n",
      "3              0.0              0.0  \n",
      "4              0.0              0.0  \n",
      "\n",
      "[5 rows x 6753 columns]\n"
     ]
    }
   ],
   "source": [
    "# Frequency counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(products['reviews'])\n",
    "print(X_train_counts.shape)\n",
    "\n",
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "word_count_df = pd.DataFrame(X_train_tfidf.toarray())\n",
    "word_count_df = word_count_df.add_prefix('word_count_')\n",
    "products = pd.concat([products, word_count_df], axis=1)\n",
    "\n",
    "print(products.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us explore what the sample example above looks like after these 2 transformations. Here, each entry in the **word_count** column is a dictionary where the key is the word and the value is a count of the number of times the word occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract sentiments\n",
    "\n",
    "We will **ignore** all reviews with *rating = 3*, since they tend to have a neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1053, 6753)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will assign reviews with a rating of 4 or higher to be *positive* reviews, while the ones with rating of 2 or lower are *negative*. For the sentiment column, we use +1 for the positive class label and -1 for the negative class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>word_count_0</th>\n",
       "      <th>word_count_1</th>\n",
       "      <th>word_count_2</th>\n",
       "      <th>word_count_3</th>\n",
       "      <th>word_count_4</th>\n",
       "      <th>word_count_5</th>\n",
       "      <th>word_count_6</th>\n",
       "      <th>...</th>\n",
       "      <th>word_count_6741</th>\n",
       "      <th>word_count_6742</th>\n",
       "      <th>word_count_6743</th>\n",
       "      <th>word_count_6744</th>\n",
       "      <th>word_count_6745</th>\n",
       "      <th>word_count_6746</th>\n",
       "      <th>word_count_6747</th>\n",
       "      <th>word_count_6748</th>\n",
       "      <th>word_count_6749</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I initially had trouble deciding between the p...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Paperwhite voyage, no regrets!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allow me to preface this with a little history...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>One Simply Could Not Ask For More</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am enjoying it so far Great for reading Had ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Great for those that just want an e-reader</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I bought one of the first Paperwhites and have...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Love / Hate relationship</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have to say upfront  I dont like coroporate ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I LOVE IT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6754 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  rating  \\\n",
       "0  I initially had trouble deciding between the p...     5.0   \n",
       "1  Allow me to preface this with a little history...     5.0   \n",
       "2  I am enjoying it so far Great for reading Had ...     4.0   \n",
       "3  I bought one of the first Paperwhites and have...     5.0   \n",
       "4  I have to say upfront  I dont like coroporate ...     5.0   \n",
       "\n",
       "                                        title  word_count_0  word_count_1  \\\n",
       "0              Paperwhite voyage, no regrets!           0.0           0.0   \n",
       "1           One Simply Could Not Ask For More           0.0           0.0   \n",
       "2  Great for those that just want an e-reader           0.0           0.0   \n",
       "3                    Love / Hate relationship           0.0           0.0   \n",
       "4                                   I LOVE IT           0.0           0.0   \n",
       "\n",
       "   word_count_2  word_count_3  word_count_4  word_count_5  word_count_6  ...  \\\n",
       "0           0.0           0.0           0.0           0.0           0.0  ...   \n",
       "1           0.0           0.0           0.0           0.0           0.0  ...   \n",
       "2           0.0           0.0           0.0           0.0           0.0  ...   \n",
       "3           0.0           0.0           0.0           0.0           0.0  ...   \n",
       "4           0.0           0.0           0.0           0.0           0.0  ...   \n",
       "\n",
       "   word_count_6741  word_count_6742  word_count_6743  word_count_6744  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_count_6745  word_count_6746  word_count_6747  word_count_6748  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_count_6749  sentiment  \n",
       "0              0.0          1  \n",
       "1              0.0          1  \n",
       "2              0.0          1  \n",
       "3              0.0          1  \n",
       "4              0.0          1  \n",
       "\n",
       "[5 rows x 6754 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'sentiment'}>]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View number of positive and negative sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see that the dataset contains an extra column called **sentiment** which is either positive (+1) or negative (-1).\n",
    "\n",
    "Note, there are significantly more positive reviews than negative reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match number of positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 977 positive reviews\n",
      "There are 76 positive reviews\n",
      "[Update] There are 76 positive reviews\n"
     ]
    }
   ],
   "source": [
    "# Report number of positive examples\n",
    "# add code here: positive_sent = \n",
    "#print('There are {} positive reviews'.format(len(positive_sent)))\n",
    "\n",
    "# Report number of negative examples\n",
    "# add code here: negative_sent =\n",
    "#print('There are {} negative reviews'.format(len(negative_sent)))\n",
    "\n",
    "# Sample number of negative example from positive examples using dr.sample()(# positive > # negative)\n",
    "# add code here: positive_sample = \n",
    "#print('[Update] There are {} positive reviews'.format(len(positive_sample)))\n",
    "\n",
    "# Merge positive and negative examples and update products dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform a train/test split with 80% of the data in the training set and 20% of the data in the test set. We use `seed=1` so that everyone gets the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a sentiment classifier with logistic regression\n",
    "\n",
    "We will now use logistic regression to create a sentiment classifier on the training data. This model will use the column **word_count** as a feature and the column **sentiment** as the target. We will use `validation_set=None` to obtain same results as everyone else.\n",
    "\n",
    "**Note:** This line may take 1-2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count_0</th>\n",
       "      <th>word_count_1</th>\n",
       "      <th>word_count_2</th>\n",
       "      <th>word_count_3</th>\n",
       "      <th>word_count_4</th>\n",
       "      <th>word_count_5</th>\n",
       "      <th>word_count_6</th>\n",
       "      <th>word_count_7</th>\n",
       "      <th>word_count_8</th>\n",
       "      <th>word_count_9</th>\n",
       "      <th>...</th>\n",
       "      <th>word_count_6740</th>\n",
       "      <th>word_count_6741</th>\n",
       "      <th>word_count_6742</th>\n",
       "      <th>word_count_6743</th>\n",
       "      <th>word_count_6744</th>\n",
       "      <th>word_count_6745</th>\n",
       "      <th>word_count_6746</th>\n",
       "      <th>word_count_6747</th>\n",
       "      <th>word_count_6748</th>\n",
       "      <th>word_count_6749</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6750 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_count_0  word_count_1  word_count_2  word_count_3  word_count_4  \\\n",
       "229            0.0           0.0           0.0           0.0           0.0   \n",
       "1020           0.0           0.0           0.0           0.0           0.0   \n",
       "170            0.0           0.0           0.0           0.0           0.0   \n",
       "781            0.0           0.0           0.0           0.0           0.0   \n",
       "211            0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "      word_count_5  word_count_6  word_count_7  word_count_8  word_count_9  \\\n",
       "229            0.0           0.0           0.0           0.0           0.0   \n",
       "1020           0.0           0.0           0.0           0.0           0.0   \n",
       "170            0.0           0.0           0.0           0.0           0.0   \n",
       "781            0.0           0.0           0.0           0.0           0.0   \n",
       "211            0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "      ...  word_count_6740  word_count_6741  word_count_6742  word_count_6743  \\\n",
       "229   ...              0.0              0.0              0.0              0.0   \n",
       "1020  ...              0.0              0.0              0.0              0.0   \n",
       "170   ...              0.0              0.0              0.0              0.0   \n",
       "781   ...              0.0              0.0              0.0              0.0   \n",
       "211   ...              0.0              0.0              0.0              0.0   \n",
       "\n",
       "      word_count_6744  word_count_6745  word_count_6746  word_count_6747  \\\n",
       "229               0.0              0.0              0.0              0.0   \n",
       "1020              0.0              0.0              0.0              0.0   \n",
       "170               0.0              0.0              0.0              0.0   \n",
       "781               0.0              0.0              0.0              0.0   \n",
       "211               0.0              0.0              0.0              0.0   \n",
       "\n",
       "      word_count_6748  word_count_6749  \n",
       "229               0.0              0.0  \n",
       "1020              0.0              0.0  \n",
       "170               0.0              0.0  \n",
       "781               0.0              0.0  \n",
       "211               0.0              0.0  \n",
       "\n",
       "[5 rows x 6750 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aside**. You may get a warning to the effect of \"Terminated due to numerical difficulties --- this model may not be ideal\". It means that the quality metric (to be covered in Module 3) failed to improve in the last iteration of the run. The difficulty arises as the sentiment model puts too much weight on extremely rare words. A way to rectify this is to apply regularization, to be covered in Module 4. Regularization lessens the effect of extremely rare words. For the purpose of this assignment, however, please proceed with the model above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fitted the model, we can extract the weights (coefficients) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of `6750` coefficients in the model. Recall from the lecture that positive weights $w_j$ correspond to weights that cause positive sentiment, while negative weights correspond to negative sentiment. \n",
    "\n",
    "Fill in the following block of code to calculate how many *weights* are positive ( >= 0). (**Hint**: Use numpy to sum the weights and check *weights* must be positive ( >= 0))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive weights: 5651 \n",
      "Number of negative weights: 1099 \n"
     ]
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Question:** How many weights are >= 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with logistic regression\n",
    "\n",
    "Now that a model is trained, we can make predictions on the **test data**. In this section, we will explore this in the context of 3 examples in the test dataset.  We refer to this set of 3 examples as the **sample_test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013    5.0\n",
      "1001    5.0\n",
      "172     5.0\n",
      "Name: rating, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>word_count_0</th>\n",
       "      <th>word_count_1</th>\n",
       "      <th>word_count_2</th>\n",
       "      <th>word_count_3</th>\n",
       "      <th>word_count_4</th>\n",
       "      <th>word_count_5</th>\n",
       "      <th>word_count_6</th>\n",
       "      <th>...</th>\n",
       "      <th>word_count_6740</th>\n",
       "      <th>word_count_6741</th>\n",
       "      <th>word_count_6742</th>\n",
       "      <th>word_count_6743</th>\n",
       "      <th>word_count_6744</th>\n",
       "      <th>word_count_6745</th>\n",
       "      <th>word_count_6746</th>\n",
       "      <th>word_count_6747</th>\n",
       "      <th>word_count_6748</th>\n",
       "      <th>word_count_6749</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>I bought these for a couple of reasonsFirst I ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I hate having to shove headphones into my brai...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>I bought these for a couple of reasonsFirst I ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I hate having to shove headphones into my brai...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>I am not a casual user of ondemand content and...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This box is a GAME CHANGER for on demand conte...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 6753 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reviews  rating  \\\n",
       "1013  I bought these for a couple of reasonsFirst I ...     5.0   \n",
       "1001  I bought these for a couple of reasonsFirst I ...     5.0   \n",
       "172   I am not a casual user of ondemand content and...     5.0   \n",
       "\n",
       "                                                  title  word_count_0  \\\n",
       "1013  I hate having to shove headphones into my brai...           0.0   \n",
       "1001  I hate having to shove headphones into my brai...           0.0   \n",
       "172   This box is a GAME CHANGER for on demand conte...           0.0   \n",
       "\n",
       "      word_count_1  word_count_2  word_count_3  word_count_4  word_count_5  \\\n",
       "1013           0.0           0.0           0.0           0.0           0.0   \n",
       "1001           0.0           0.0           0.0           0.0           0.0   \n",
       "172            0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "      word_count_6  ...  word_count_6740  word_count_6741  word_count_6742  \\\n",
       "1013           0.0  ...              0.0              0.0              0.0   \n",
       "1001           0.0  ...              0.0              0.0              0.0   \n",
       "172            0.0  ...              0.0              0.0              0.0   \n",
       "\n",
       "      word_count_6743  word_count_6744  word_count_6745  word_count_6746  \\\n",
       "1013              0.0              0.0              0.0              0.0   \n",
       "1001              0.0              0.0              0.0              0.0   \n",
       "172               0.0              0.0              0.0              0.0   \n",
       "\n",
       "      word_count_6747  word_count_6748  word_count_6749  \n",
       "1013              0.0              0.0              0.0  \n",
       "1001              0.0              0.0              0.0  \n",
       "172               0.0              0.0              0.0  \n",
       "\n",
       "[3 rows x 6753 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dig deeper into the first row of the **sample_test_data**. Here's the full review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I bought these for a couple of reasonsFirst I wanted an earbud that was NOT designed as noise cancelling I hate having to shove headphones into my brain to use them Apparently a lot of people are under the assumption that these are supposed to be noise cancelling or something which they are not They are simple earbuds I hate not being able to hear what is going on around me and dont feel safe in public using headphones that block everything else out These are designed just like the old style earbuds that you stick in your ears but they are more comfortable Maybe I have small ears or something but they could never fall out or dislodge from my ears They dont cancel the outside noise but they sit in my ears exactly as they are supposed to so the sound travels right into my earsSecond I really like the magnets and tangle free aspects of the headphones I use headphones while I work and the magnets allow me to hang the headphones easily when I am finished with them The flat cord and magnets also mean the headphones never really tangle when you put them in a bag or wherever Awesome designFinally the sound I get out of these seems pretty average I would compare them to the stock Apple iPhone earbuds or a set of Sony earbuds Nothing special They are only 25 and a lot of that is the fact these were just released and that you are paying for the design as far as magnets in the ear buds and the nice flat cable Dont expect them to perform like 100 headphones because they arent designed to perform like that They are just a nice simple set of earbuds that will sound good to most people The magnets and tangle free cord are awesome and they are really quite comfortableRead more'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data['reviews'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That review seems pretty positive.\n",
    "\n",
    "Now, let's see what the next row of the **sample_test_data** looks like. As we could guess from the sentiment (-1), the review is quite negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I bought these for a couple of reasonsFirst I wanted an earbud that was NOT designed as noise cancelling I hate having to shove headphones into my brain to use them Apparently a lot of people are under the assumption that these are supposed to be noise cancelling or something which they are not They are simple earbuds I hate not being able to hear what is going on around me and dont feel safe in public using headphones that block everything else out These are designed just like the old style earbuds that you stick in your ears but they are more comfortable Maybe I have small ears or something but they could never fall out or dislodge from my ears They dont cancel the outside noise but they sit in my ears exactly as they are supposed to so the sound travels right into my earsSecond I really like the magnets and tangle free aspects of the headphones I use headphones while I work and the magnets allow me to hang the headphones easily when I am finished with them The flat cord and magnets also mean the headphones never really tangle when you put them in a bag or wherever Awesome designFinally the sound I get out of these seems pretty average I would compare them to the stock Apple iPhone earbuds or a set of Sony earbuds Nothing special They are only 25 and a lot of that is the fact these were just released and that you are paying for the design as far as magnets in the ear buds and the nice flat cable Dont expect them to perform like 100 headphones because they arent designed to perform like that They are just a nice simple set of earbuds that will sound good to most people The magnets and tangle free cord are awesome and they are really quite comfortableRead more'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data['reviews'].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now make a **class** prediction for the **sample_test_data**. The `sentiment_model` should predict **+1** if the sentiment is positive and **-1** if the sentiment is negative. Recall from the lecture that the **score** (sometimes called **margin**) for the logistic regression model  is defined as:\n",
    "\n",
    "$$\n",
    "\\mbox{score}_i = \\mathbf{w}^T h(\\mathbf{x}_i)\n",
    "$$ \n",
    "\n",
    "where $h(\\mathbf{x}_i)$ represents the features for example $i$.  We will write some code to obtain the **scores**. For each row, the **score** (or margin) is a number in the range **[-inf, inf]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44561858 0.44561858 0.30868726]\n"
     ]
    }
   ],
   "source": [
    "scores = sample_test_data.loc[:, sample_test_data.columns.str.startswith('word_count_')].to_numpy() @ weights.reshape((-1)) + sentiment_model.intercept_\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting sentiment\n",
    "\n",
    "These scores can be used to make class predictions as follows:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & \\mathbf{w}^T h(\\mathbf{x}_i) > 0 \\\\\n",
    "      -1 & \\mathbf{w}^T h(\\mathbf{x}_i) \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Using scores, write code to calculate $\\hat{y}$, the class predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to verify that the class predictions obtained by your calculations are the same as that obtained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class predictions:\n",
      "[1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**: Make sure your class predictions match with the one obtained from above.\n",
    "\n",
    "### Probability predictions\n",
    "\n",
    "Recall from the lectures that we can also calculate the probability predictions from the scores using:\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))}.\n",
    "$$\n",
    "\n",
    "Using the variable **scores** calculated previously, write code to calculate the probability that a sentiment is positive using the above formula. For each row, the probabilities should be a number in the range **[0, 1]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60959701 0.60959701 0.5765648 ]\n"
     ]
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**: Make sure your probability predictions match the ones obtained from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class predictions for y=1:\n",
      "[0.60959701 0.60959701 0.5765648 ]\n"
     ]
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Discussion Question:** Of the three data points in **sample_test_data**, which one (first, second, or third) has the **lowest probability** of being classified as a positive review?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most positive (and negative) review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn to examining the full test dataset, **test_data**, and use Numpy argsort to form predictions on all of the test data points for faster performance.\n",
    "\n",
    "Using the `sentiment_model`, find the 20 reviews in the entire **test_data** with the **highest probability** of being classified as a **positive review**. We refer to these as the \"most positive reviews.\"\n",
    "\n",
    "To calculate these top-20 reviews, use the following steps:\n",
    "1.  Make probability predictions on **test_data** using the `sentiment_model`. (**Hint:** When you call `.predict` to make predictions on the test data.)\n",
    "2.  Sort the data according to those predictions and pick the top 20. (**Hint:** You can use indexing [-topn:] to find the top k rows sorted according to the value of a specified column.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20 18 27  6 17 13 23  8  9 25 26  4 16 22 14  7 30 28  2  0]\n",
      "                                                reviews  rating  \\\n",
      "342        Works great to protect the Kindle from drops     5.0   \n",
      "738   The Ultimate Bluetooth speakerI have multiple ...     5.0   \n",
      "842   I was not overly impressed with this system I ...     2.0   \n",
      "62    Im a huge fan of the Echo family I have two Ec...     5.0   \n",
      "371   Really awesome tablet for my 5 year olds and w...     4.0   \n",
      "677   I have been enjoying the amazon tap for two we...     5.0   \n",
      "833   I really havent had a chance to use this much ...     4.0   \n",
      "968   As good as the Echo is the Echo Voice Remote s...     2.0   \n",
      "876   Could not get it to work properly I put the ap...     1.0   \n",
      "776   hard to use and does not support Guam online i...     1.0   \n",
      "267   In this day and age of rectangles with screens...     2.0   \n",
      "469   Just really thought it would have been more us...     2.0   \n",
      "217                                                 Too     2.0   \n",
      "210   According to the info the Paperwhite charges f...     4.0   \n",
      "134   DONT BUY a reburbished Kindle Ive had to retur...     1.0   \n",
      "213                                     very overpriced     2.0   \n",
      "591   Im thinking this must of been a fluke it never...     2.0   \n",
      "971   Worked great for a few weeks then completely s...     1.0   \n",
      "1046  Dont bother paying for one or getting a replac...     2.0   \n",
      "1033  I dont know whats wrong with fire tv remotes b...     1.0   \n",
      "\n",
      "                                                  title  word_count_0  \\\n",
      "342                                          Five Stars           0.0   \n",
      "738   The Perfect Bluetooth Speaker...Plus So Much M...           0.0   \n",
      "842                             I returned this product           0.0   \n",
      "62                         Great upgrade for aesthetics           0.0   \n",
      "371                 Good tablet, could use improvements           0.0   \n",
      "677                      There is always something more           0.0   \n",
      "833                                         cool gadget           0.0   \n",
      "968   Has Trouble Understanding Commands, Volume Con...           0.0   \n",
      "876                            Would not work properly!           0.0   \n",
      "776                                  Not a good product           0.0   \n",
      "267                                            Just Bad           0.0   \n",
      "469                                       Not impressed           0.0   \n",
      "217                                           Two Stars           0.0   \n",
      "210         because I like it, but feel it's overpriced           0.0   \n",
      "134                     Don't buy a refurbished Kindle!           0.0   \n",
      "213                                           Two Stars           0.0   \n",
      "591                                     It never worked           0.0   \n",
      "971                                  Dead after 3 weeks           0.0   \n",
      "1046                                      Don't Buy It.           0.0   \n",
      "1033                       Amazon fire tv remote sucks!           0.0   \n",
      "\n",
      "      word_count_1  word_count_2  word_count_3  word_count_4  word_count_5  \\\n",
      "342            0.0           0.0           0.0           0.0           0.0   \n",
      "738            0.0           0.0           0.0           0.0           0.0   \n",
      "842            0.0           0.0           0.0           0.0           0.0   \n",
      "62             0.0           0.0           0.0           0.0           0.0   \n",
      "371            0.0           0.0           0.0           0.0           0.0   \n",
      "677            0.0           0.0           0.0           0.0           0.0   \n",
      "833            0.0           0.0           0.0           0.0           0.0   \n",
      "968            0.0           0.0           0.0           0.0           0.0   \n",
      "876            0.0           0.0           0.0           0.0           0.0   \n",
      "776            0.0           0.0           0.0           0.0           0.0   \n",
      "267            0.0           0.0           0.0           0.0           0.0   \n",
      "469            0.0           0.0           0.0           0.0           0.0   \n",
      "217            0.0           0.0           0.0           0.0           0.0   \n",
      "210            0.0           0.0           0.0           0.0           0.0   \n",
      "134            0.0           0.0           0.0           0.0           0.0   \n",
      "213            0.0           0.0           0.0           0.0           0.0   \n",
      "591            0.0           0.0           0.0           0.0           0.0   \n",
      "971            0.0           0.0           0.0           0.0           0.0   \n",
      "1046           0.0           0.0           0.0           0.0           0.0   \n",
      "1033           0.0           0.0           0.0           0.0           0.0   \n",
      "\n",
      "      word_count_6  ...  word_count_6740  word_count_6741  word_count_6742  \\\n",
      "342            0.0  ...              0.0              0.0              0.0   \n",
      "738            0.0  ...              0.0              0.0              0.0   \n",
      "842            0.0  ...              0.0              0.0              0.0   \n",
      "62             0.0  ...              0.0              0.0              0.0   \n",
      "371            0.0  ...              0.0              0.0              0.0   \n",
      "677            0.0  ...              0.0              0.0              0.0   \n",
      "833            0.0  ...              0.0              0.0              0.0   \n",
      "968            0.0  ...              0.0              0.0              0.0   \n",
      "876            0.0  ...              0.0              0.0              0.0   \n",
      "776            0.0  ...              0.0              0.0              0.0   \n",
      "267            0.0  ...              0.0              0.0              0.0   \n",
      "469            0.0  ...              0.0              0.0              0.0   \n",
      "217            0.0  ...              0.0              0.0              0.0   \n",
      "210            0.0  ...              0.0              0.0              0.0   \n",
      "134            0.0  ...              0.0              0.0              0.0   \n",
      "213            0.0  ...              0.0              0.0              0.0   \n",
      "591            0.0  ...              0.0              0.0              0.0   \n",
      "971            0.0  ...              0.0              0.0              0.0   \n",
      "1046           0.0  ...              0.0              0.0              0.0   \n",
      "1033           0.0  ...              0.0              0.0              0.0   \n",
      "\n",
      "      word_count_6743  word_count_6744  word_count_6745  word_count_6746  \\\n",
      "342               0.0              0.0              0.0              0.0   \n",
      "738               0.0              0.0              0.0              0.0   \n",
      "842               0.0              0.0              0.0              0.0   \n",
      "62                0.0              0.0              0.0              0.0   \n",
      "371               0.0              0.0              0.0              0.0   \n",
      "677               0.0              0.0              0.0              0.0   \n",
      "833               0.0              0.0              0.0              0.0   \n",
      "968               0.0              0.0              0.0              0.0   \n",
      "876               0.0              0.0              0.0              0.0   \n",
      "776               0.0              0.0              0.0              0.0   \n",
      "267               0.0              0.0              0.0              0.0   \n",
      "469               0.0              0.0              0.0              0.0   \n",
      "217               0.0              0.0              0.0              0.0   \n",
      "210               0.0              0.0              0.0              0.0   \n",
      "134               0.0              0.0              0.0              0.0   \n",
      "213               0.0              0.0              0.0              0.0   \n",
      "591               0.0              0.0              0.0              0.0   \n",
      "971               0.0              0.0              0.0              0.0   \n",
      "1046              0.0              0.0              0.0              0.0   \n",
      "1033              0.0              0.0              0.0              0.0   \n",
      "\n",
      "      word_count_6747  word_count_6748  word_count_6749  \n",
      "342               0.0              0.0              0.0  \n",
      "738               0.0              0.0              0.0  \n",
      "842               0.0              0.0              0.0  \n",
      "62                0.0              0.0              0.0  \n",
      "371               0.0              0.0              0.0  \n",
      "677               0.0              0.0              0.0  \n",
      "833               0.0              0.0              0.0  \n",
      "968               0.0              0.0              0.0  \n",
      "876               0.0              0.0              0.0  \n",
      "776               0.0              0.0              0.0  \n",
      "267               0.0              0.0              0.0  \n",
      "469               0.0              0.0              0.0  \n",
      "217               0.0              0.0              0.0  \n",
      "210               0.0              0.0              0.0  \n",
      "134               0.0              0.0              0.0  \n",
      "213               0.0              0.0              0.0  \n",
      "591               0.0              0.0              0.0  \n",
      "971               0.0              0.0              0.0  \n",
      "1046              0.0              0.0              0.0  \n",
      "1033              0.0              0.0              0.0  \n",
      "\n",
      "[20 rows x 6753 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the class probabilities for the test set\n",
    "y_prob = sentiment_model.predict_proba(X_test_sentiment)\n",
    "\n",
    "# Sort the test set in descending order of their probabilities of being positive\n",
    "idx = np.argsort(-y_prob[:, 1])\n",
    "\n",
    "# Get the indices of the 20 most positive reviews\n",
    "idx_most_positive = idx[-20:] \n",
    "print(idx_most_positive)\n",
    "\n",
    "# Get the corresponding reviews from the test set\n",
    "most_positive_reviews = X_test.iloc[idx_most_positive]\n",
    "print(most_positive_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Question**: Which of the following products are represented in the 20 most positive reviews? [multiple choice]\n",
    "\n",
    "\n",
    "Now, let us repeat this exercise to find the \"most negative reviews.\" Use the prediction probabilities to find the  20 reviews in the **test_data** with the **lowest probability** of being classified as a **positive review**. Repeat the same steps above but make sure you **sort in the opposite order**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                reviews  rating  \\\n",
      "678   We have had the fullsize Echo for over a year ...     5.0   \n",
      "1026  I bought these for a couple of reasonsFirst I ...     5.0   \n",
      "1013  I bought these for a couple of reasonsFirst I ...     5.0   \n",
      "1001  I bought these for a couple of reasonsFirst I ...     5.0   \n",
      "819   I love using this as a speaker for my MacBook ...     5.0   \n",
      "172   I am not a casual user of ondemand content and...     5.0   \n",
      "796   We have the tap and the echo I wouldnt buy ano...     4.0   \n",
      "837   As a bluetooth speaker the Tap rocks The sound...     5.0   \n",
      "507   Love having someone to take notes for me and p...     4.0   \n",
      "512   Love the Dot Hate the Tap Portable This device...     2.0   \n",
      "460   Great product for intro to an AI device Cant w...     5.0   \n",
      "342        Works great to protect the Kindle from drops     5.0   \n",
      "738   The Ultimate Bluetooth speakerI have multiple ...     5.0   \n",
      "842   I was not overly impressed with this system I ...     2.0   \n",
      "62    Im a huge fan of the Echo family I have two Ec...     5.0   \n",
      "371   Really awesome tablet for my 5 year olds and w...     4.0   \n",
      "677   I have been enjoying the amazon tap for two we...     5.0   \n",
      "833   I really havent had a chance to use this much ...     4.0   \n",
      "968   As good as the Echo is the Echo Voice Remote s...     2.0   \n",
      "876   Could not get it to work properly I put the ap...     1.0   \n",
      "\n",
      "                                                  title  word_count_0  \\\n",
      "678                                 Great portabe Alexa           0.0   \n",
      "1026  I hate having to shove headphones into my brai...           0.0   \n",
      "1013  I hate having to shove headphones into my brai...           0.0   \n",
      "1001  I hate having to shove headphones into my brai...           0.0   \n",
      "819                                     Great for music           0.0   \n",
      "172   This box is a GAME CHANGER for on demand conte...           0.0   \n",
      "796                           Ok but the echo is better           0.0   \n",
      "837                     Fun and Useful with Great Sound           0.0   \n",
      "507                                         Big helper!           0.0   \n",
      "512                 Love the Dot, Hate the Tap Portable           0.0   \n",
      "460                            Great Item for Beginners           0.0   \n",
      "342                                          Five Stars           0.0   \n",
      "738   The Perfect Bluetooth Speaker...Plus So Much M...           0.0   \n",
      "842                             I returned this product           0.0   \n",
      "62                         Great upgrade for aesthetics           0.0   \n",
      "371                 Good tablet, could use improvements           0.0   \n",
      "677                      There is always something more           0.0   \n",
      "833                                         cool gadget           0.0   \n",
      "968   Has Trouble Understanding Commands, Volume Con...           0.0   \n",
      "876                            Would not work properly!           0.0   \n",
      "\n",
      "      word_count_1  word_count_2  word_count_3  word_count_4  word_count_5  \\\n",
      "678            0.0           0.0           0.0           0.0           0.0   \n",
      "1026           0.0           0.0           0.0           0.0           0.0   \n",
      "1013           0.0           0.0           0.0           0.0           0.0   \n",
      "1001           0.0           0.0           0.0           0.0           0.0   \n",
      "819            0.0           0.0           0.0           0.0           0.0   \n",
      "172            0.0           0.0           0.0           0.0           0.0   \n",
      "796            0.0           0.0           0.0           0.0           0.0   \n",
      "837            0.0           0.0           0.0           0.0           0.0   \n",
      "507            0.0           0.0           0.0           0.0           0.0   \n",
      "512            0.0           0.0           0.0           0.0           0.0   \n",
      "460            0.0           0.0           0.0           0.0           0.0   \n",
      "342            0.0           0.0           0.0           0.0           0.0   \n",
      "738            0.0           0.0           0.0           0.0           0.0   \n",
      "842            0.0           0.0           0.0           0.0           0.0   \n",
      "62             0.0           0.0           0.0           0.0           0.0   \n",
      "371            0.0           0.0           0.0           0.0           0.0   \n",
      "677            0.0           0.0           0.0           0.0           0.0   \n",
      "833            0.0           0.0           0.0           0.0           0.0   \n",
      "968            0.0           0.0           0.0           0.0           0.0   \n",
      "876            0.0           0.0           0.0           0.0           0.0   \n",
      "\n",
      "      word_count_6  ...  word_count_6740  word_count_6741  word_count_6742  \\\n",
      "678            0.0  ...              0.0              0.0              0.0   \n",
      "1026           0.0  ...              0.0              0.0              0.0   \n",
      "1013           0.0  ...              0.0              0.0              0.0   \n",
      "1001           0.0  ...              0.0              0.0              0.0   \n",
      "819            0.0  ...              0.0              0.0              0.0   \n",
      "172            0.0  ...              0.0              0.0              0.0   \n",
      "796            0.0  ...              0.0              0.0              0.0   \n",
      "837            0.0  ...              0.0              0.0              0.0   \n",
      "507            0.0  ...              0.0              0.0              0.0   \n",
      "512            0.0  ...              0.0              0.0              0.0   \n",
      "460            0.0  ...              0.0              0.0              0.0   \n",
      "342            0.0  ...              0.0              0.0              0.0   \n",
      "738            0.0  ...              0.0              0.0              0.0   \n",
      "842            0.0  ...              0.0              0.0              0.0   \n",
      "62             0.0  ...              0.0              0.0              0.0   \n",
      "371            0.0  ...              0.0              0.0              0.0   \n",
      "677            0.0  ...              0.0              0.0              0.0   \n",
      "833            0.0  ...              0.0              0.0              0.0   \n",
      "968            0.0  ...              0.0              0.0              0.0   \n",
      "876            0.0  ...              0.0              0.0              0.0   \n",
      "\n",
      "      word_count_6743  word_count_6744  word_count_6745  word_count_6746  \\\n",
      "678               0.0              0.0              0.0              0.0   \n",
      "1026              0.0              0.0              0.0              0.0   \n",
      "1013              0.0              0.0              0.0              0.0   \n",
      "1001              0.0              0.0              0.0              0.0   \n",
      "819               0.0              0.0              0.0              0.0   \n",
      "172               0.0              0.0              0.0              0.0   \n",
      "796               0.0              0.0              0.0              0.0   \n",
      "837               0.0              0.0              0.0              0.0   \n",
      "507               0.0              0.0              0.0              0.0   \n",
      "512               0.0              0.0              0.0              0.0   \n",
      "460               0.0              0.0              0.0              0.0   \n",
      "342               0.0              0.0              0.0              0.0   \n",
      "738               0.0              0.0              0.0              0.0   \n",
      "842               0.0              0.0              0.0              0.0   \n",
      "62                0.0              0.0              0.0              0.0   \n",
      "371               0.0              0.0              0.0              0.0   \n",
      "677               0.0              0.0              0.0              0.0   \n",
      "833               0.0              0.0              0.0              0.0   \n",
      "968               0.0              0.0              0.0              0.0   \n",
      "876               0.0              0.0              0.0              0.0   \n",
      "\n",
      "      word_count_6747  word_count_6748  word_count_6749  \n",
      "678               0.0              0.0              0.0  \n",
      "1026              0.0              0.0              0.0  \n",
      "1013              0.0              0.0              0.0  \n",
      "1001              0.0              0.0              0.0  \n",
      "819               0.0              0.0              0.0  \n",
      "172               0.0              0.0              0.0  \n",
      "796               0.0              0.0              0.0  \n",
      "837               0.0              0.0              0.0  \n",
      "507               0.0              0.0              0.0  \n",
      "512               0.0              0.0              0.0  \n",
      "460               0.0              0.0              0.0  \n",
      "342               0.0              0.0              0.0  \n",
      "738               0.0              0.0              0.0  \n",
      "842               0.0              0.0              0.0  \n",
      "62                0.0              0.0              0.0  \n",
      "371               0.0              0.0              0.0  \n",
      "677               0.0              0.0              0.0  \n",
      "833               0.0              0.0              0.0  \n",
      "968               0.0              0.0              0.0  \n",
      "876               0.0              0.0              0.0  \n",
      "\n",
      "[20 rows x 6753 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get the indices of the 20 most negative reviews\n",
    "idx_most_negative = idx[:20]\n",
    "\n",
    "# Get the corresponding reviews from the test set\n",
    "most_negative_reviews = X_test.iloc[idx_most_negative]\n",
    "print(most_negative_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question**: Which of the following products are represented in the 20 most negative reviews?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute accuracy of the classifier\n",
    "\n",
    "We will now evaluate the accuracy of the trained classifier. Recall that the accuracy is given by\n",
    "\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified examples}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "This can be computed as follows:\n",
    "\n",
    "* **Step 1:** Use the trained model to compute class predictions (**Hint:** Use the `predict` method)\n",
    "* **Step 2:** Count the number of data points when the predicted class labels match the ground truth labels (called `true_labels` below).\n",
    "* **Step 3:** Divide the total number of correct predictions by the total number of data points in the dataset.\n",
    "\n",
    "Complete the function below to compute the classification accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_classification_accuracy(model, data, true_labels):\n",
    "    # First get the predictions\n",
    "    ## add code here\n",
    "    \n",
    "    # Compute the number of correctly classified examples\n",
    "    ## add code here\n",
    "\n",
    "    # Then compute accuracy by dividing num_correct by total number of examples\n",
    "    ## add code here\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute the classification accuracy of the **sentiment_model** on the **test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8709677419354839"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Question**: What is the accuracy of the **sentiment_model** on the **test_data**? Round your answer to 2 decimal places (e.g. 0.76).\n",
    "\n",
    "**Discussion Question**: Does a higher accuracy value on the **training_data** always imply that the classifier is better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn another classifier with fewer words\n",
    "\n",
    "There were a lot of words in the model we trained above. We will now train a simpler logistic regression model using only a subset of words that occur in the reviews. For this assignment, we selected a 20 words to work with. These are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'amazing', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(significant_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_words = count_vect.get_feature_names_out() # newer version of sklearn\n",
    "all_words = count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each review, we will use the **word_count** column and trim out all words that are **not** in the **significant_words** list above. We will use the [SArray dictionary trim by keys functionality]( https://dato.com/products/create/docs/generated/graphlab.SArray.dict_trim_by_keys.html). Note that we are performing this on both the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count_310</th>\n",
       "      <th>word_count_515</th>\n",
       "      <th>word_count_1016</th>\n",
       "      <th>word_count_1137</th>\n",
       "      <th>word_count_1838</th>\n",
       "      <th>word_count_2039</th>\n",
       "      <th>word_count_2192</th>\n",
       "      <th>word_count_2764</th>\n",
       "      <th>word_count_3522</th>\n",
       "      <th>word_count_3662</th>\n",
       "      <th>word_count_3666</th>\n",
       "      <th>word_count_3901</th>\n",
       "      <th>word_count_4164</th>\n",
       "      <th>word_count_4416</th>\n",
       "      <th>word_count_4680</th>\n",
       "      <th>word_count_5069</th>\n",
       "      <th>word_count_6489</th>\n",
       "      <th>word_count_6538</th>\n",
       "      <th>word_count_6648</th>\n",
       "      <th>word_count_6671</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>0.032729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031833</td>\n",
       "      <td>0.025422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_count_310  word_count_515  word_count_1016  word_count_1137  \\\n",
       "229         0.000000             0.0              0.0              0.0   \n",
       "1020        0.032729             0.0              0.0              0.0   \n",
       "170         0.000000             0.0              0.0              0.0   \n",
       "781         0.000000             0.0              0.0              0.0   \n",
       "211         0.000000             0.0              0.0              0.0   \n",
       "\n",
       "      word_count_1838  word_count_2039  word_count_2192  word_count_2764  \\\n",
       "229               0.0              0.0              0.0              0.0   \n",
       "1020              0.0              0.0              0.0              0.0   \n",
       "170               0.0              0.0              0.0              0.0   \n",
       "781               0.0              0.0              0.0              0.0   \n",
       "211               0.0              0.0              0.0              0.0   \n",
       "\n",
       "      word_count_3522  word_count_3662  word_count_3666  word_count_3901  \\\n",
       "229               0.0              0.0         0.000000         0.108244   \n",
       "1020              0.0              0.0         0.000000         0.000000   \n",
       "170               0.0              0.0         0.000000         0.000000   \n",
       "781               0.0              0.0         0.221342         0.000000   \n",
       "211               0.0              0.0         0.000000         0.000000   \n",
       "\n",
       "      word_count_4164  word_count_4416  word_count_4680  word_count_5069  \\\n",
       "229          0.000000              0.0              0.0              0.0   \n",
       "1020         0.039824              0.0              0.0              0.0   \n",
       "170          0.000000              0.0              0.0              0.0   \n",
       "781          0.000000              0.0              0.0              0.0   \n",
       "211          0.000000              0.0              0.0              0.0   \n",
       "\n",
       "      word_count_6489  word_count_6538  word_count_6648  word_count_6671  \n",
       "229          0.155978         0.000000         0.000000         0.000000  \n",
       "1020         0.000000         0.000000         0.031833         0.025422  \n",
       "170          0.000000         0.000000         0.000000         0.000000  \n",
       "781          0.000000         0.000000         0.000000         0.114759  \n",
       "211          0.000000         0.109139         0.000000         0.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract significant words and split train/test sets\n",
    "\n",
    "sig_word_set = set(significant_words)\n",
    "sig_idx = [i for i, e in enumerate(all_words) if e in sig_word_set]\n",
    "\n",
    "X_train_sig = X_train_sentiment.iloc[:, sig_idx]\n",
    "X_test_sig = X_test_sentiment.iloc[:, sig_idx]\n",
    "\n",
    "X_train_sig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the first example of the dataset looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I typically dont post reviews however dont waste your money on this case I got it on Friday and started using it that evening Its now Thursday and the case is peeling at the edges the fabric around the camera hole has started bubbling and the felt on the inside edge is wearing off i have not had any issues with it standing on its own like other people have mentioned I am giving this a two star mainly because it is still functional I am tempted to send it back but I like the functionality of this case'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['reviews'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **word_count** column had been working with before looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_count_0       0.0\n",
       "word_count_1       0.0\n",
       "word_count_2       0.0\n",
       "word_count_3       0.0\n",
       "word_count_4       0.0\n",
       "                  ... \n",
       "word_count_6745    0.0\n",
       "word_count_6746    0.0\n",
       "word_count_6747    0.0\n",
       "word_count_6748    0.0\n",
       "word_count_6749    0.0\n",
       "Name: 229, Length: 6750, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sentiment.iloc[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are only working with a subset of these words, the column **word_count_subset** is a subset of the above dictionary. In this example, only 2 `significant words` are present in this review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_count_310     0.000000\n",
       "word_count_515     0.000000\n",
       "word_count_1016    0.000000\n",
       "word_count_1137    0.000000\n",
       "word_count_1838    0.000000\n",
       "word_count_2039    0.000000\n",
       "word_count_2192    0.000000\n",
       "word_count_2764    0.000000\n",
       "word_count_3522    0.000000\n",
       "word_count_3662    0.000000\n",
       "word_count_3666    0.000000\n",
       "word_count_3901    0.108244\n",
       "word_count_4164    0.000000\n",
       "word_count_4416    0.000000\n",
       "word_count_4680    0.000000\n",
       "word_count_5069    0.000000\n",
       "word_count_6489    0.155978\n",
       "word_count_6538    0.000000\n",
       "word_count_6648    0.000000\n",
       "word_count_6671    0.000000\n",
       "Name: 229, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sig.iloc[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a logistic regression model on a subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now build a classifier with **word_count_subset** with significant words as the feature and **sentiment** as the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(random_state=0)\n"
     ]
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the classification accuracy using the `get_classification_accuracy` function you implemented earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5483870967741935"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will inspect the weights (coefficients) of the **simple_model**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07104329  0.03778847  0.         -0.06656962 -0.19825001  0.47819648\n",
      "  -0.15147854  0.93499694  0.04017237  1.0106324   0.11614478 -0.1889335\n",
      "   0.05475834  0.54754391  0.04338208 -0.09360217 -0.42243534  0.15243118\n",
      "  -0.19370058 -0.1932077 ]]\n"
     ]
    }
   ],
   "source": [
    "print(simple_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort the coefficients (in descending order) by the **value** to obtain the coefficients with the most positive effect on the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0106324   0.93499694  0.54754391  0.47819648  0.15243118  0.11614478\n",
      "   0.07104329  0.05475834  0.04338208  0.04017237  0.03778847  0.\n",
      "  -0.06656962 -0.09360217 -0.15147854 -0.1889335  -0.1932077  -0.19370058\n",
      "  -0.19825001 -0.42243534]]\n"
     ]
    }
   ],
   "source": [
    "print(-np.sort(-simple_model.coef_, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Question**: Consider the coefficients of **simple_model**. There should be 21 of them, an intercept term + one for each word in **significant_words**. How many of the 20 coefficients (corresponding to the 20 **significant_words** and *excluding the intercept term*) are positive for the `simple_model`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "num_positive_weights = np.sum(simple_model.coef_ >= 0)\n",
    "print(num_positive_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Question**: Are the positive words in the **simple_model** (let us call them `positive_significant_words`) also positive words in the **sentiment_model**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compare the accuracy of the **sentiment_model** and the **simple_model** using the `get_classification_accuracy` method you implemented above.\n",
    "\n",
    "First, compute the classification accuracy of the **sentiment_model** on the **train_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9834710743801653\n"
     ]
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compute the classification accuracy of the **simple_model** on the **train_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Question**: Which model (**sentiment_model** or **simple_model**) has higher accuracy on the TRAINING set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will repeat this exercise on the **test_data**. Start by computing the classification accuracy of the **sentiment_model** on the **test_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8709677419354839\n"
     ]
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will compute the classification accuracy of the **simple_model** on the **test_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5483870967741935"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Question**: Which model (**sentiment_model** or **simple_model**) has higher accuracy on the TEST set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Question**: Comment out the sention on 'Match number of positive and negative reviews' and re-run the notebook. Which model (**sentiment_model** or **simple_model**) has higher accuracy on the TEST set? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Majority class prediction\n",
    "\n",
    "It is quite common to use the **majority class classifier** as the a baseline (or reference) model for comparison with your classifier model. The majority classifier model predicts the majority class for all data points. At the very least, you should healthily beat the majority class classifier, otherwise, the model is (usually) pointless.\n",
    "\n",
    "What is the majority class in the **train_data**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the accuracy of the majority class classifier on **test_data**.\n",
    "\n",
    "**Discussion Question**: Enter the accuracy of the majority class classifier model on the **test_data**. Round your answer to two decimal places (e.g. 0.76)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment    0.451613\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Question**: Is the **sentiment_model** definitely better than the majority class classifier (the baseline)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "85463d1bb2888979eba71184c8d462df281b59dd3aecce6d9ffe8745b11b3329"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
